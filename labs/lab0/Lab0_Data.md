## Lab 0. Data

When working with natural language processing, the data is the most important thing. 
Not only the quality of your data but also its fitness to the particular task can drastically change the quality of your model.
Depending on the task, you might want to need just _raw text_ or _annotated text_. 

### Raw text data

In the era of the internet, getting raw text data should not be a problem anymore. You can scrap the web to get millions of texts.

Here are some examples of the data sources:

- [Project Gutenberg](https://www.gutenberg.org/) - many books in English (for free)
- [Wikimedia Downloads](https://dumps.wikimedia.org/) - basically, you can download the whole Wikipedia for any language
- [Reddit](https://www.reddit.com/) - popular Internet community, contains various thematic "subreddits" that can be scrapped for data
- [Twitter](https://twitter.com/home) - great source of real user texts, need to request the API access 

### Annotated text data

Annotation of texts takes a lot of time and resources. Thus, only a few want to share their work to the world for free.
Depending on the task, you will need a specific annotation. There are several standards for some tasks.

Here are some examples:

- [Univeral Dependencies](https://universaldependencies.org/) - morphologically and syntactically annotated data for over 70 languages
- [Europarl: A Parallel Corpus for Statistical Machine Translation](https://www.statmt.org/europarl/) - parallel corpus of translations in 21 European languages (Estonian included)
- [The Big Bad NLP Database](https://quantumstat.com/dataset/dataset.html) - many more NLP datasets
